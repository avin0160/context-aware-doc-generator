{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93212574",
   "metadata": {},
   "source": [
    "# Context-Aware Documentation Generator - Training Notebook\n",
    "\n",
    "This notebook demonstrates how to fine-tune the Phi-3 model for code documentation generation using QLoRA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40478c6",
   "metadata": {},
   "source": [
    "## Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b68342f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (run this in Colab)\n",
    "!pip install -q transformers datasets peft bitsandbytes accelerate\n",
    "!pip install -q sentence-transformers faiss-cpu\n",
    "!pip install -q tree-sitter tree-sitter-python tree-sitter-javascript\n",
    "!pip install -q gitpython loguru tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c466f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import TrainingArguments, Trainer\n",
    "import logging\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Add project root to path (adjust if needed)\n",
    "project_root = Path.cwd()\n",
    "if 'notebooks' in str(project_root):\n",
    "    project_root = project_root.parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# Import our modules\n",
    "from src.llm import create_documentation_generator\n",
    "from src.parser import create_parser\n",
    "from src.rag import create_rag_system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7772df",
   "metadata": {},
   "source": [
    "## Check GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d673e340",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "else:\n",
    "    print(\"Running on CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab094192",
   "metadata": {},
   "source": [
    "## Create Training Dataset\n",
    "\n",
    "We'll create a synthetic dataset of code-docstring pairs for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd05856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample training data - in practice, you'd collect real examples\n",
    "training_examples = [\n",
    "    {\n",
    "        \"code\": \"def add_numbers(a, b):\\n    return a + b\",\n",
    "        \"language\": \"python\",\n",
    "        \"docstring\": '\"\"\"\\nAdd two numbers together.\\n\\nArgs:\\n    a (int|float): First number\\n    b (int|float): Second number\\n\\nReturns:\\n    int|float: Sum of the two numbers\\n\"\"\"'\n",
    "    },\n",
    "    {\n",
    "        \"code\": \"def factorial(n):\\n    if n <= 1:\\n        return 1\\n    return n * factorial(n - 1)\",\n",
    "        \"language\": \"python\",\n",
    "        \"docstring\": '\"\"\"\\nCalculate the factorial of a number using recursion.\\n\\nArgs:\\n    n (int): Non-negative integer to calculate factorial for\\n\\nReturns:\\n    int: Factorial of n\\n\\nRaises:\\n    RecursionError: If n is too large and exceeds recursion limit\\n\"\"\"'\n",
    "    },\n",
    "    {\n",
    "        \"code\": \"class Rectangle:\\n    def __init__(self, width, height):\\n        self.width = width\\n        self.height = height\\n\\n    def area(self):\\n        return self.width * self.height\",\n",
    "        \"language\": \"python\",\n",
    "        \"docstring\": '\"\"\"\\nA rectangle class for geometric calculations.\\n\\nAttributes:\\n    width (float): Width of the rectangle\\n    height (float): Height of the rectangle\\n\"\"\"'\n",
    "    },\n",
    "    {\n",
    "        \"code\": \"function validateEmail(email) {\\n    const re = /^[^\\\\s@]+@[^\\\\s@]+\\\\.[^\\\\s@]+$/;\\n    return re.test(email);\\n}\",\n",
    "        \"language\": \"javascript\",\n",
    "        \"docstring\": '/**\\n * Validate an email address using regex.\\n * \\n * @param {string} email - The email address to validate\\n * @returns {boolean} True if email is valid, false otherwise\\n */'\n",
    "    },\n",
    "    {\n",
    "        \"code\": \"public int binarySearch(int[] arr, int target) {\\n    int left = 0, right = arr.length - 1;\\n    while (left <= right) {\\n        int mid = left + (right - left) / 2;\\n        if (arr[mid] == target) return mid;\\n        if (arr[mid] < target) left = mid + 1;\\n        else right = mid - 1;\\n    }\\n    return -1;\\n}\",\n",
    "        \"language\": \"java\",\n",
    "        \"docstring\": '/**\\n * Perform binary search on a sorted array.\\n * \\n * @param arr The sorted array to search in\\n * @param target The value to search for\\n * @return Index of target if found, -1 otherwise\\n */'\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"Created {len(training_examples)} training examples\")\n",
    "print(\"\\nExample:\")\n",
    "print(f\"Code: {training_examples[0]['code']}\")\n",
    "print(f\"Docstring: {training_examples[0]['docstring']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdcfe07",
   "metadata": {},
   "source": [
    "## Initialize Model and Prepare for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9652522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize documentation generator\n",
    "print(\"Initializing documentation generator...\")\n",
    "doc_generator = create_documentation_generator()\n",
    "\n",
    "# Prepare model for training\n",
    "print(\"Preparing model for LoRA training...\")\n",
    "doc_generator.prepare_for_training()\n",
    "\n",
    "print(\"Model prepared successfully!\")\n",
    "print(f\"Model device: {doc_generator.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cb8388",
   "metadata": {},
   "source": [
    "## Format Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd510dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format training examples for the model\n",
    "formatted_examples = []\n",
    "\n",
    "for example in training_examples:\n",
    "    # Create prompt\n",
    "    prompt = f\"\"\"Generate a docstring for this {example['language']} code:\n",
    "\n",
    "```{example['language']}\n",
    "{example['code']}\n",
    "```\n",
    "\n",
    "Docstring:\"\"\"\n",
    "    \n",
    "    # Format as training example\n",
    "    formatted_example = {\n",
    "        \"input\": prompt,\n",
    "        \"output\": example['docstring']\n",
    "    }\n",
    "    formatted_examples.append(formatted_example)\n",
    "\n",
    "# Convert to HuggingFace dataset format\n",
    "training_data = doc_generator.create_training_dataset(formatted_examples)\n",
    "\n",
    "print(f\"Formatted {len(training_data)} training examples\")\n",
    "print(\"\\nFirst formatted example:\")\n",
    "print(training_data[0]['text'][:200] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37c865d",
   "metadata": {},
   "source": [
    "## Setup Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f601bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "dataset = Dataset.from_list(training_data)\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./phi3-docstring-lora\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    warmup_steps=10,\n",
    "    learning_rate=2e-4,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    remove_unused_columns=False,\n",
    "    dataloader_pin_memory=False,\n",
    ")\n",
    "\n",
    "print(\"Training configuration:\")\n",
    "print(f\"- Epochs: {training_args.num_train_epochs}\")\n",
    "print(f\"- Batch size: {training_args.per_device_train_batch_size}\")\n",
    "print(f\"- Learning rate: {training_args.learning_rate}\")\n",
    "print(f\"- FP16: {training_args.fp16}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17414fd6",
   "metadata": {},
   "source": [
    "## Data Collator for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d091029",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    \"\"\"Tokenize the training examples.\"\"\"\n",
    "    return doc_generator.tokenizer(\n",
    "        examples['text'],\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=512,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "# Tokenize dataset\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Data collator\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=doc_generator.tokenizer,\n",
    "    mlm=False,  # Causal language modeling\n",
    ")\n",
    "\n",
    "print(\"Dataset tokenized and data collator prepared\")\n",
    "print(f\"Tokenized dataset size: {len(tokenized_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eef2e14",
   "metadata": {},
   "source": [
    "## Initialize Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abeb9fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trainer\n",
    "trainer = Trainer(\n",
    "    model=doc_generator.model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=doc_generator.tokenizer,\n",
    ")\n",
    "\n",
    "print(\"Trainer initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a046111",
   "metadata": {},
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0966c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: This is a minimal example with very few samples\n",
    "# In practice, you'd want hundreds or thousands of examples\n",
    "print(\"Starting training...\")\n",
    "print(\"⚠️ This is a demonstration with minimal data. For production, use much more training data.\")\n",
    "\n",
    "try:\n",
    "    trainer.train()\n",
    "    print(\"✅ Training completed successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Training error: {e}\")\n",
    "    print(\"This might be due to insufficient GPU memory or other configuration issues.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579a798c",
   "metadata": {},
   "source": [
    "## Save the Fine-tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f843ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "output_dir = \"./fine_tuned_phi3_docstring\"\n",
    "try:\n",
    "    doc_generator.save_model(output_dir)\n",
    "    print(f\"✅ Model saved to {output_dir}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error saving model: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e28721",
   "metadata": {},
   "source": [
    "## Test the Fine-tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6139439b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a new code example\n",
    "test_code = \"\"\"\n",
    "def bubble_sort(arr):\n",
    "    n = len(arr)\n",
    "    for i in range(n):\n",
    "        for j in range(0, n - i - 1):\n",
    "            if arr[j] > arr[j + 1]:\n",
    "                arr[j], arr[j + 1] = arr[j + 1], arr[j]\n",
    "    return arr\n",
    "\"\"\"\n",
    "\n",
    "print(\"Testing the model with new code:\")\n",
    "print(\"Code:\")\n",
    "print(test_code)\n",
    "\n",
    "# Generate docstring\n",
    "try:\n",
    "    docstring = doc_generator.generate_docstring(\n",
    "        code=test_code.strip(),\n",
    "        language=\"python\",\n",
    "        context=\"\",\n",
    "        style=\"google\"\n",
    "    )\n",
    "    \n",
    "    print(\"\\nGenerated Docstring:\")\n",
    "    print(docstring)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error generating docstring: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d97090f",
   "metadata": {},
   "source": [
    "## Training Tips and Best Practices\n",
    "\n",
    "### For Better Results:\n",
    "\n",
    "1. **Larger Dataset**: Use thousands of high-quality code-docstring pairs\n",
    "2. **Data Quality**: Ensure docstrings follow consistent style guidelines\n",
    "3. **Language Diversity**: Include examples from multiple programming languages\n",
    "4. **Code Complexity**: Include simple functions to complex classes and modules\n",
    "5. **Domain Specific**: Fine-tune on code from your specific domain (web dev, ML, etc.)\n",
    "\n",
    "### Hardware Requirements:\n",
    "- **GPU**: NVIDIA GPU with at least 8GB VRAM (16GB+ recommended)\n",
    "- **RAM**: 16GB+ system RAM\n",
    "- **Storage**: 10GB+ free space for models and datasets\n",
    "\n",
    "### Data Collection Sources:\n",
    "- Open source repositories with good documentation\n",
    "- Code documentation datasets (CodeSearchNet, etc.)\n",
    "- Manual curation of high-quality examples\n",
    "- Synthetic data generation with GPT-4 or similar models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5713eac7",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25eb145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple evaluation on held-out examples\n",
    "test_examples = [\n",
    "    {\n",
    "        \"code\": \"def max_element(lst):\\n    return max(lst) if lst else None\",\n",
    "        \"language\": \"python\"\n",
    "    },\n",
    "    {\n",
    "        \"code\": \"function isEven(num) {\\n    return num % 2 === 0;\\n}\",\n",
    "        \"language\": \"javascript\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"Evaluating model on test examples:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i, example in enumerate(test_examples, 1):\n",
    "    print(f\"\\nTest Example {i}:\")\n",
    "    print(f\"Language: {example['language']}\")\n",
    "    print(f\"Code: {example['code']}\")\n",
    "    \n",
    "    try:\n",
    "        docstring = doc_generator.generate_docstring(\n",
    "            code=example['code'],\n",
    "            language=example['language'],\n",
    "            context=\"\",\n",
    "            style=\"google\"\n",
    "        )\n",
    "        print(f\"Generated Docstring: {docstring}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    \n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e977b6a",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Collect More Data**: Gather a larger, more diverse dataset\n",
    "2. **Hyperparameter Tuning**: Experiment with different learning rates, batch sizes, etc.\n",
    "3. **Evaluation Metrics**: Implement BLEU, ROUGE, or other text generation metrics\n",
    "4. **A/B Testing**: Compare generated documentation quality with human-written docs\n",
    "5. **Domain Adaptation**: Fine-tune for specific programming domains or frameworks\n",
    "6. **Integration**: Deploy the fine-tuned model in the main application"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
