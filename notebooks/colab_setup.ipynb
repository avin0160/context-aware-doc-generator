{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2114bbee",
   "metadata": {},
   "source": [
    "# 🚀 Context-Aware Code Documentation Generator - Colab Setup\n",
    "\n",
    "This notebook sets up the Context-Aware Code Documentation Generator in Google Colab.\n",
    "\n",
    "**Before running**: Upload the entire project folder to Colab or clone from GitHub."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc97f8f0",
   "metadata": {},
   "source": [
    "## Step 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ba90a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install core dependencies first\n",
    "!pip install -q fastapi uvicorn[standard] streamlit pydantic\n",
    "print(\"✅ Core web framework dependencies installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4d1b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install tree-sitter and language parsers\n",
    "!pip install -q tree-sitter\n",
    "!pip install -q tree-sitter-python tree-sitter-javascript tree-sitter-java tree-sitter-go tree-sitter-cpp\n",
    "print(\"✅ Tree-sitter and language parsers installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1294f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install RAG and ML dependencies\n",
    "!pip install -q sentence-transformers faiss-cpu gitpython\n",
    "print(\"✅ RAG and Git dependencies installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf66412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install LLM and fine-tuning dependencies\n",
    "!pip install -q transformers torch peft bitsandbytes accelerate\n",
    "print(\"✅ LLM and fine-tuning dependencies installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ef6fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install utility dependencies\n",
    "!pip install -q python-multipart aiofiles python-dotenv loguru tqdm\n",
    "print(\"✅ Utility dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44c10cd",
   "metadata": {},
   "source": [
    "## Step 2: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7629254",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set environment variables\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "os.environ['HF_HOME'] = './models'\n",
    "\n",
    "# Create directories\n",
    "directories = ['models', 'temp', 'output', 'logs', 'indexes']\n",
    "for directory in directories:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "# Check GPU\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    print(f\"🖥️  GPU: {gpu_name} ({gpu_memory:.1f} GB)\")\n",
    "else:\n",
    "    print(\"🖥️  Using CPU (GPU not available)\")\n",
    "\n",
    "print(\"✅ Environment setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9bb416",
   "metadata": {},
   "source": [
    "## Step 3: Test Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292e94c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test critical imports\n",
    "try:\n",
    "    import tree_sitter\n",
    "    print(\"✅ tree-sitter imported\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ tree-sitter import failed: {e}\")\n",
    "\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    print(\"✅ sentence-transformers imported\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ sentence-transformers import failed: {e}\")\n",
    "\n",
    "try:\n",
    "    from transformers import AutoTokenizer\n",
    "    print(\"✅ transformers imported\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ transformers import failed: {e}\")\n",
    "\n",
    "try:\n",
    "    import faiss\n",
    "    print(\"✅ faiss imported\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ faiss import failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b123a7",
   "metadata": {},
   "source": [
    "## Step 4: Import Project Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50cf74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add project to Python path\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Adjust path if needed - assumes you're in the project root\n",
    "project_root = Path.cwd()\n",
    "if project_root.name != 'context-aware-doc-generator':\n",
    "    # Look for the project directory\n",
    "    for p in [Path.cwd() / 'context-aware-doc-generator', Path('/content/context-aware-doc-generator')]:\n",
    "        if p.exists():\n",
    "            project_root = p\n",
    "            break\n",
    "\n",
    "sys.path.insert(0, str(project_root))\n",
    "print(f\"📁 Project root: {project_root}\")\n",
    "\n",
    "# Test project imports\n",
    "try:\n",
    "    from src.parser import create_parser\n",
    "    print(\"✅ Parser module imported\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ Parser import failed: {e}\")\n",
    "\n",
    "try:\n",
    "    from src.rag import create_rag_system\n",
    "    print(\"✅ RAG module imported\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ RAG import failed: {e}\")\n",
    "\n",
    "try:\n",
    "    from src.llm import create_documentation_generator\n",
    "    print(\"✅ LLM module imported\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ LLM import failed: {e}\")\n",
    "    print(\"Note: This might fail due to GPU memory constraints in Colab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761179cf",
   "metadata": {},
   "source": [
    "## Step 5: Quick Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4de51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick functionality test\n",
    "print(\"🧪 Running quick functionality test...\")\n",
    "\n",
    "# Test parser\n",
    "try:\n",
    "    parser = create_parser()\n",
    "    \n",
    "    # Test language detection\n",
    "    test_file = \"test.py\"\n",
    "    language = parser.detect_language(test_file)\n",
    "    print(f\"✅ Language detection works: {test_file} -> {language}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Parser test failed: {e}\")\n",
    "\n",
    "# Test RAG system\n",
    "try:\n",
    "    rag_system = create_rag_system()\n",
    "    print(\"✅ RAG system initialized (this may take a moment to download models)\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ RAG system test failed: {e}\")\n",
    "\n",
    "print(\"\\n🎉 Setup validation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d90d8be",
   "metadata": {},
   "source": [
    "## Step 6: Ready to Use!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7cf11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🚀 Context-Aware Code Documentation Generator is ready!\")\n",
    "print(\"\\n📖 What you can do now:\")\n",
    "print(\"\\n1. 📝 Open examples.ipynb for usage demonstrations\")\n",
    "print(\"2. 🎓 Open training.ipynb for model fine-tuning\")\n",
    "print(\"3. 🌐 Start web interface:\")\n",
    "print(\"   - API: !uvicorn src.api:app --host 0.0.0.0 --port 8000\")\n",
    "print(\"   - Frontend: !streamlit run src/frontend.py --server.port 8501\")\n",
    "print(\"4. 💻 Use CLI: !python main.py --help\")\n",
    "print(\"\\n5. 🧪 Quick example:\")\n",
    "print(\"   parser = create_parser()\")\n",
    "print(\"   # Create a Python file and parse it\")\n",
    "print(\"\\n🎯 The system is optimized for Colab and should work with the free tier!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b533aa2c",
   "metadata": {},
   "source": [
    "## Optional: Start Web Interface\n",
    "\n",
    "Uncomment and run these cells to start the web interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f06a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Start FastAPI backend in background\n",
    "# import subprocess\n",
    "# import time\n",
    "# \n",
    "# # Start API server\n",
    "# api_process = subprocess.Popen([\n",
    "#     'uvicorn', 'src.api:app', \n",
    "#     '--host', '0.0.0.0', \n",
    "#     '--port', '8000'\n",
    "# ])\n",
    "# \n",
    "# print(\"🚀 API server starting...\")\n",
    "# time.sleep(5)\n",
    "# print(\"✅ API server should be running on port 8000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc35443a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Start Streamlit frontend\n",
    "# !streamlit run src/frontend.py --server.port 8501 --server.address 0.0.0.0"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
