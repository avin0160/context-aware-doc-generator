{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfcfc7b4",
   "metadata": {},
   "source": [
    "# Context-Aware Documentation Generator - Examples and Usage\n",
    "\n",
    "This notebook demonstrates how to use the Context-Aware Code Documentation Generator with various examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2215eacb",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad584282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages if running in Colab\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd()\n",
    "if 'notebooks' in str(project_root):\n",
    "    project_root = project_root.parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "print(f\"Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0afbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our modules\n",
    "from src.parser import create_parser\n",
    "from src.rag import create_rag_system\n",
    "from src.llm import create_documentation_generator\n",
    "from src.git_handler import create_git_handler\n",
    "\n",
    "import json\n",
    "import tempfile\n",
    "import logging\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64aa2a31",
   "metadata": {},
   "source": [
    "## Example 1: Basic Code Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf55a45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample Python code file\n",
    "sample_python_code = '''\n",
    "def fibonacci(n):\n",
    "    if n <= 1:\n",
    "        return n\n",
    "    return fibonacci(n-1) + fibonacci(n-2)\n",
    "\n",
    "class Calculator:\n",
    "    def __init__(self):\n",
    "        self.history = []\n",
    "    \n",
    "    def add(self, a, b):\n",
    "        result = a + b\n",
    "        self.history.append(f\"{a} + {b} = {result}\")\n",
    "        return result\n",
    "    \n",
    "    def multiply(self, a, b):\n",
    "        result = a * b\n",
    "        self.history.append(f\"{a} * {b} = {result}\")\n",
    "        return result\n",
    "'''\n",
    "\n",
    "# Write to temporary file\n",
    "with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:\n",
    "    f.write(sample_python_code)\n",
    "    temp_file_path = f.name\n",
    "\n",
    "print(f\"Created temporary file: {temp_file_path}\")\n",
    "print(\"Sample code:\")\n",
    "print(sample_python_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b28c52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parser\n",
    "parser = create_parser()\n",
    "\n",
    "# Parse the file\n",
    "parsed_result = parser.parse_file(temp_file_path)\n",
    "\n",
    "if parsed_result:\n",
    "    print(\"\\n📊 Parsing Results:\")\n",
    "    print(f\"Language: {parsed_result['language']}\")\n",
    "    print(f\"Functions found: {len(parsed_result['functions'])}\")\n",
    "    print(f\"Classes found: {len(parsed_result['classes'])}\")\n",
    "    \n",
    "    print(\"\\n🔧 Functions:\")\n",
    "    for func in parsed_result['functions']:\n",
    "        print(f\"  - {func['name']} (lines {func['start_line']}-{func['end_line']})\")\n",
    "    \n",
    "    print(\"\\n📦 Classes:\")\n",
    "    for cls in parsed_result['classes']:\n",
    "        print(f\"  - {cls['name']} (lines {cls['start_line']}-{cls['end_line']})\")\n",
    "else:\n",
    "    print(\"❌ Failed to parse file\")\n",
    "\n",
    "# Cleanup\n",
    "os.unlink(temp_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2257b824",
   "metadata": {},
   "source": [
    "## Example 2: RAG System Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dc70bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mock parsed codebase\n",
    "mock_codebase = {\n",
    "    'files': {\n",
    "        'math_utils.py': {\n",
    "            'language': 'python',\n",
    "            'file_path': 'math_utils.py',\n",
    "            'functions': [\n",
    "                {\n",
    "                    'name': 'add',\n",
    "                    'text': 'def add(a, b):\\n    return a + b',\n",
    "                    'start_line': 1,\n",
    "                    'end_line': 2\n",
    "                },\n",
    "                {\n",
    "                    'name': 'multiply',\n",
    "                    'text': 'def multiply(a, b):\\n    return a * b',\n",
    "                    'start_line': 4,\n",
    "                    'end_line': 5\n",
    "                }\n",
    "            ],\n",
    "            'classes': [],\n",
    "            'imports': ['import math'],\n",
    "            'comments': []\n",
    "        },\n",
    "        'string_utils.py': {\n",
    "            'language': 'python',\n",
    "            'file_path': 'string_utils.py',\n",
    "            'functions': [\n",
    "                {\n",
    "                    'name': 'reverse_string',\n",
    "                    'text': 'def reverse_string(s):\\n    return s[::-1]',\n",
    "                    'start_line': 1,\n",
    "                    'end_line': 2\n",
    "                }\n",
    "            ],\n",
    "            'classes': [],\n",
    "            'imports': [],\n",
    "            'comments': []\n",
    "        }\n",
    "    },\n",
    "    'summary': {\n",
    "        'total_files': 2,\n",
    "        'languages': ['python'],\n",
    "        'total_functions': 3,\n",
    "        'total_classes': 0\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Mock codebase created with:\")\n",
    "print(f\"- {mock_codebase['summary']['total_files']} files\")\n",
    "print(f\"- {mock_codebase['summary']['total_functions']} functions\")\n",
    "print(f\"- Languages: {', '.join(mock_codebase['summary']['languages'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a8a144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize RAG system\n",
    "print(\"Initializing RAG system...\")\n",
    "rag_system = create_rag_system()\n",
    "\n",
    "# Prepare code chunks\n",
    "print(\"Preparing code chunks...\")\n",
    "code_chunks = rag_system.prepare_code_chunks(mock_codebase)\n",
    "\n",
    "print(f\"\\n📊 Prepared {len(code_chunks)} code chunks:\")\n",
    "for i, chunk in enumerate(code_chunks):\n",
    "    print(f\"  {i+1}. {chunk['type']} - {chunk['metadata'].get('name', 'N/A')}\")\n",
    "\n",
    "# Build index\n",
    "print(\"\\nBuilding FAISS index...\")\n",
    "rag_system.build_index(code_chunks)\n",
    "print(\"✅ Index built successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5b8bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test search functionality\n",
    "search_queries = [\n",
    "    \"mathematical operations\",\n",
    "    \"string manipulation\",\n",
    "    \"addition function\",\n",
    "    \"reverse text\"\n",
    "]\n",
    "\n",
    "print(\"🔍 Testing search functionality:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for query in search_queries:\n",
    "    print(f\"\\nQuery: '{query}'\")\n",
    "    results = rag_system.search(query, k=2)\n",
    "    \n",
    "    for i, result in enumerate(results, 1):\n",
    "        chunk = result['chunk']\n",
    "        score = result['score']\n",
    "        print(f\"  {i}. Score: {score:.3f} | Type: {chunk['type']} | {chunk['metadata'].get('name', 'N/A')}\")\n",
    "        print(f\"     Content preview: {chunk['content'][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6902fe4a",
   "metadata": {},
   "source": [
    "## Example 3: Documentation Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2726c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize documentation generator\n",
    "print(\"Initializing documentation generator...\")\n",
    "print(\"⚠️  This may take a few minutes to download the model on first run\")\n",
    "\n",
    "try:\n",
    "    doc_generator = create_documentation_generator()\n",
    "    print(\"✅ Documentation generator initialized successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error initializing generator: {e}\")\n",
    "    print(\"This might be due to memory constraints or network issues.\")\n",
    "    doc_generator = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83d0b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test docstring generation\n",
    "if doc_generator:\n",
    "    test_functions = [\n",
    "        {\n",
    "            'code': 'def quicksort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    pivot = arr[len(arr) // 2]\\n    left = [x for x in arr if x < pivot]\\n    middle = [x for x in arr if x == pivot]\\n    right = [x for x in arr if x > pivot]\\n    return quicksort(left) + middle + quicksort(right)',\n",
    "            'language': 'python',\n",
    "            'name': 'quicksort'\n",
    "        },\n",
    "        {\n",
    "            'code': 'class BankAccount:\\n    def __init__(self, balance=0):\\n        self._balance = balance\\n    \\n    def deposit(self, amount):\\n        self._balance += amount\\n        return self._balance\\n    \\n    def withdraw(self, amount):\\n        if amount <= self._balance:\\n            self._balance -= amount\\n            return self._balance\\n        raise ValueError(\"Insufficient funds\")',\n",
    "            'language': 'python',\n",
    "            'name': 'BankAccount'\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(\"🔖 Generating docstrings:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for func in test_functions:\n",
    "        print(f\"\\n📝 Generating documentation for: {func['name']}\")\n",
    "        print(f\"Language: {func['language']}\")\n",
    "        print(\"\\nOriginal code:\")\n",
    "        print(func['code'])\n",
    "        \n",
    "        try:\n",
    "            # Get context from RAG\n",
    "            context = rag_system.get_context_for_documentation(\n",
    "                func['code'], \n",
    "                'function' if 'def ' in func['code'] else 'class'\n",
    "            )\n",
    "            \n",
    "            # Generate docstring\n",
    "            docstring = doc_generator.generate_docstring(\n",
    "                code=func['code'],\n",
    "                language=func['language'],\n",
    "                context=context,\n",
    "                style='google'\n",
    "            )\n",
    "            \n",
    "            print(\"\\n🎯 Generated docstring:\")\n",
    "            print(docstring)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error generating docstring: {e}\")\n",
    "        \n",
    "        print(\"-\" * 50)\n",
    "else:\n",
    "    print(\"⏭️  Skipping docstring generation (model not available)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09ae265",
   "metadata": {},
   "source": [
    "## Example 4: Processing a GitHub Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff4244b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of processing a small GitHub repository\n",
    "# Using a simple, lightweight repository for demonstration\n",
    "\n",
    "# Initialize git handler\n",
    "git_handler = create_git_handler()\n",
    "\n",
    "# Example repository (replace with any small public repo)\n",
    "repo_url = \"https://github.com/octocat/Hello-World.git\"\n",
    "\n",
    "print(f\"📥 Attempting to clone repository: {repo_url}\")\n",
    "print(\"⚠️  This requires internet connection and the repository to be accessible\")\n",
    "\n",
    "try:\n",
    "    # Clone repository\n",
    "    repo_path = git_handler.clone_repository(repo_url)\n",
    "    print(f\"✅ Repository cloned to: {repo_path}\")\n",
    "    \n",
    "    # Get repository info\n",
    "    repo_info = git_handler.get_repository_info(repo_path)\n",
    "    print(f\"\\n📊 Repository Information:\")\n",
    "    print(f\"  - Files: {repo_info.get('files_count', 0)}\")\n",
    "    print(f\"  - Size: {repo_info.get('total_size_mb', 0)} MB\")\n",
    "    print(f\"  - Languages: {', '.join(repo_info.get('languages', []))}\")\n",
    "    \n",
    "    # Parse the codebase\n",
    "    if repo_info.get('files_count', 0) > 0:\n",
    "        print(\"\\n🔍 Parsing codebase...\")\n",
    "        parsed_codebase = parser.parse_codebase(repo_path)\n",
    "        \n",
    "        print(f\"\\n📈 Parsing Results:\")\n",
    "        print(f\"  - Files processed: {parsed_codebase['summary']['total_files']}\")\n",
    "        print(f\"  - Functions found: {parsed_codebase['summary']['total_functions']}\")\n",
    "        print(f\"  - Classes found: {parsed_codebase['summary']['total_classes']}\")\n",
    "        print(f\"  - Languages: {', '.join(parsed_codebase['summary']['languages'])}\")\n",
    "        \n",
    "        # Show some file details\n",
    "        if parsed_codebase['files']:\n",
    "            print(\"\\n📁 Files analyzed:\")\n",
    "            for file_path, file_data in list(parsed_codebase['files'].items())[:3]:  # Show first 3 files\n",
    "                print(f\"  - {file_path} ({file_data['language']})\")\n",
    "                if file_data['functions']:\n",
    "                    print(f\"    Functions: {[f['name'] for f in file_data['functions']]}\")\n",
    "                if file_data['classes']:\n",
    "                    print(f\"    Classes: {[c['name'] for c in file_data['classes']]}\")\n",
    "    \n",
    "    # Cleanup\n",
    "    git_handler.cleanup(repo_path)\n",
    "    print(\"\\n🧹 Cleaned up temporary files\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error processing repository: {e}\")\n",
    "    print(\"This might be due to network issues, repository access, or parsing errors.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadac576",
   "metadata": {},
   "source": [
    "## Example 5: Multi-Language Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65af6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test multi-language parsing\n",
    "code_samples = {\n",
    "    'python': '''\n",
    "def binary_search(arr, target):\n",
    "    left, right = 0, len(arr) - 1\n",
    "    while left <= right:\n",
    "        mid = (left + right) // 2\n",
    "        if arr[mid] == target:\n",
    "            return mid\n",
    "        elif arr[mid] < target:\n",
    "            left = mid + 1\n",
    "        else:\n",
    "            right = mid - 1\n",
    "    return -1\n",
    "''',\n",
    "    'javascript': '''\n",
    "function validatePassword(password) {\n",
    "    const minLength = 8;\n",
    "    const hasUpperCase = /[A-Z]/.test(password);\n",
    "    const hasLowerCase = /[a-z]/.test(password);\n",
    "    const hasNumbers = /\\d/.test(password);\n",
    "    const hasSpecialChar = /[!@#$%^&*(),.?\":{}|<>]/.test(password);\n",
    "    \n",
    "    return password.length >= minLength && \n",
    "           hasUpperCase && \n",
    "           hasLowerCase && \n",
    "           hasNumbers && \n",
    "           hasSpecialChar;\n",
    "}\n",
    "''',\n",
    "    'java': '''\n",
    "public class LinkedList<T> {\n",
    "    private Node<T> head;\n",
    "    private int size;\n",
    "    \n",
    "    private static class Node<T> {\n",
    "        T data;\n",
    "        Node<T> next;\n",
    "        \n",
    "        Node(T data) {\n",
    "            this.data = data;\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    public void add(T data) {\n",
    "        Node<T> newNode = new Node<>(data);\n",
    "        if (head == null) {\n",
    "            head = newNode;\n",
    "        } else {\n",
    "            Node<T> current = head;\n",
    "            while (current.next != null) {\n",
    "                current = current.next;\n",
    "            }\n",
    "            current.next = newNode;\n",
    "        }\n",
    "        size++;\n",
    "    }\n",
    "}\n",
    "'''\n",
    "}\n",
    "\n",
    "print(\"🌍 Testing multi-language support:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for language, code in code_samples.items():\n",
    "    print(f\"\\n📝 Language: {language.upper()}\")\n",
    "    \n",
    "    # Create temporary file\n",
    "    extensions = {'python': '.py', 'javascript': '.js', 'java': '.java'}\n",
    "    with tempfile.NamedTemporaryFile(mode='w', suffix=extensions[language], delete=False) as f:\n",
    "        f.write(code)\n",
    "        temp_file = f.name\n",
    "    \n",
    "    try:\n",
    "        # Parse the file\n",
    "        parsed = parser.parse_file(temp_file)\n",
    "        \n",
    "        if parsed:\n",
    "            print(f\"✅ Parsed successfully\")\n",
    "            print(f\"   Language detected: {parsed['language']}\")\n",
    "            print(f\"   Functions: {len(parsed['functions'])}\")\n",
    "            print(f\"   Classes: {len(parsed['classes'])}\")\n",
    "            \n",
    "            # Show function/class names\n",
    "            if parsed['functions']:\n",
    "                func_names = [f['name'] for f in parsed['functions']]\n",
    "                print(f\"   Function names: {', '.join(func_names)}\")\n",
    "            \n",
    "            if parsed['classes']:\n",
    "                class_names = [c['name'] for c in parsed['classes']]\n",
    "                print(f\"   Class names: {', '.join(class_names)}\")\n",
    "        else:\n",
    "            print(f\"❌ Failed to parse {language} code\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error parsing {language}: {e}\")\n",
    "    \n",
    "    finally:\n",
    "        # Cleanup\n",
    "        if os.path.exists(temp_file):\n",
    "            os.unlink(temp_file)\n",
    "    \n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf65a95",
   "metadata": {},
   "source": [
    "## Example 6: Complete Workflow Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334f01fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a small mock project structure\n",
    "import os\n",
    "import tempfile\n",
    "import shutil\n",
    "\n",
    "# Create temporary directory\n",
    "temp_project_dir = tempfile.mkdtemp(prefix='demo_project_')\n",
    "print(f\"📁 Created temporary project directory: {temp_project_dir}\")\n",
    "\n",
    "# Create mock project files\n",
    "files_to_create = {\n",
    "    'main.py': '''\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Main entry point for the application.\n",
    "\"\"\"\n",
    "\n",
    "from utils import helper_function\n",
    "from models import DataProcessor\n",
    "\n",
    "def main():\n",
    "    processor = DataProcessor()\n",
    "    result = processor.process([1, 2, 3, 4, 5])\n",
    "    print(f\"Result: {result}\")\n",
    "    \n",
    "    helper_result = helper_function(\"test\")\n",
    "    print(f\"Helper result: {helper_result}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "''',\n",
    "    'utils.py': '''\n",
    "def helper_function(input_string):\n",
    "    return input_string.upper()\n",
    "\n",
    "def calculate_average(numbers):\n",
    "    if not numbers:\n",
    "        return 0\n",
    "    return sum(numbers) / len(numbers)\n",
    "\n",
    "def find_max(numbers):\n",
    "    return max(numbers) if numbers else None\n",
    "''',\n",
    "    'models.py': '''\n",
    "class DataProcessor:\n",
    "    def __init__(self):\n",
    "        self.processed_count = 0\n",
    "    \n",
    "    def process(self, data):\n",
    "        self.processed_count += 1\n",
    "        return [x * 2 for x in data]\n",
    "    \n",
    "    def get_stats(self):\n",
    "        return {\"processed_count\": self.processed_count}\n",
    "\n",
    "class Config:\n",
    "    DEBUG = True\n",
    "    VERSION = \"1.0.0\"\n",
    "'''\n",
    "}\n",
    "\n",
    "# Write files\n",
    "for filename, content in files_to_create.items():\n",
    "    file_path = os.path.join(temp_project_dir, filename)\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write(content.strip())\n",
    "    print(f\"  ✅ Created {filename}\")\n",
    "\n",
    "print(f\"\\n📊 Demo project created with {len(files_to_create)} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b918166e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run complete workflow on the demo project\n",
    "print(\"🚀 Running complete documentation generation workflow:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # Step 1: Parse the entire codebase\n",
    "    print(\"\\n1️⃣ Parsing codebase...\")\n",
    "    parsed_codebase = parser.parse_codebase(temp_project_dir)\n",
    "    \n",
    "    print(f\"   ✅ Parsed {parsed_codebase['summary']['total_files']} files\")\n",
    "    print(f\"   📊 Found {parsed_codebase['summary']['total_functions']} functions\")\n",
    "    print(f\"   📦 Found {parsed_codebase['summary']['total_classes']} classes\")\n",
    "    \n",
    "    # Step 2: Build RAG index\n",
    "    print(\"\\n2️⃣ Building RAG index...\")\n",
    "    code_chunks = rag_system.prepare_code_chunks(parsed_codebase)\n",
    "    rag_system.build_index(code_chunks)\n",
    "    print(f\"   ✅ Built index with {len(code_chunks)} chunks\")\n",
    "    \n",
    "    # Step 3: Generate documentation (if model is available)\n",
    "    if doc_generator:\n",
    "        print(\"\\n3️⃣ Generating documentation...\")\n",
    "        \n",
    "        doc_count = 0\n",
    "        for file_path, file_data in parsed_codebase['files'].items():\n",
    "            print(f\"\\n   📝 Processing {os.path.basename(file_path)}:\")\n",
    "            \n",
    "            # Document functions\n",
    "            for func in file_data['functions'][:2]:  # Limit to first 2 functions per file\n",
    "                try:\n",
    "                    context = rag_system.get_context_for_documentation(\n",
    "                        func.get('text', ''), 'function'\n",
    "                    )\n",
    "                    \n",
    "                    docstring = doc_generator.generate_docstring(\n",
    "                        code=func.get('text', ''),\n",
    "                        language=file_data['language'],\n",
    "                        context=context[:100],  # Limit context for demo\n",
    "                        style='google'\n",
    "                    )\n",
    "                    \n",
    "                    print(f\"     🔧 {func['name']}: Generated docstring ({len(docstring)} chars)\")\n",
    "                    doc_count += 1\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"     ❌ Error documenting {func['name']}: {e}\")\n",
    "            \n",
    "            # Document classes\n",
    "            for cls in file_data['classes'][:1]:  # Limit to first class per file\n",
    "                try:\n",
    "                    context = rag_system.get_context_for_documentation(\n",
    "                        cls.get('text', ''), 'class'\n",
    "                    )\n",
    "                    \n",
    "                    docstring = doc_generator.generate_docstring(\n",
    "                        code=cls.get('text', ''),\n",
    "                        language=file_data['language'],\n",
    "                        context=context[:100],  # Limit context for demo\n",
    "                        style='google'\n",
    "                    )\n",
    "                    \n",
    "                    print(f\"     📦 {cls['name']}: Generated docstring ({len(docstring)} chars)\")\n",
    "                    doc_count += 1\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"     ❌ Error documenting {cls['name']}: {e}\")\n",
    "        \n",
    "        print(f\"\\n   ✅ Generated documentation for {doc_count} items\")\n",
    "        \n",
    "        # Generate markdown documentation\n",
    "        print(\"\\n4️⃣ Generating project README...\")\n",
    "        try:\n",
    "            markdown_docs = doc_generator.generate_markdown_docs(\n",
    "                parsed_codebase, \n",
    "                \"Demo project showcasing multi-file documentation generation\"\n",
    "            )\n",
    "            print(f\"   ✅ Generated README ({len(markdown_docs)} characters)\")\n",
    "            print(f\"   📄 README preview: {markdown_docs[:150]}...\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Error generating README: {e}\")\n",
    "    \n",
    "    else:\n",
    "        print(\"\\n3️⃣ ⏭️  Skipping documentation generation (model not available)\")\n",
    "    \n",
    "    print(\"\\n🎉 Workflow completed successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Workflow error: {e}\")\n",
    "\n",
    "finally:\n",
    "    # Cleanup\n",
    "    if os.path.exists(temp_project_dir):\n",
    "        shutil.rmtree(temp_project_dir)\n",
    "        print(f\"\\n🧹 Cleaned up temporary project directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e157f8a3",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "This notebook demonstrated the key capabilities of the Context-Aware Code Documentation Generator:\n",
    "\n",
    "### ✅ What We Covered:\n",
    "1. **Multi-language parsing** with tree-sitter\n",
    "2. **RAG system** for contextual understanding\n",
    "3. **Documentation generation** with Phi-3 model\n",
    "4. **GitHub repository processing**\n",
    "5. **End-to-end workflow** demonstration\n",
    "\n",
    "### 🚀 Next Steps:\n",
    "1. **Scale up**: Try with larger, real-world repositories\n",
    "2. **Fine-tune**: Use the training notebook to customize the model\n",
    "3. **Integrate**: Set up the web interface for easier usage\n",
    "4. **Customize**: Adapt prompts and styles for your specific needs\n",
    "5. **Deploy**: Use the CLI tool for batch processing\n",
    "\n",
    "### 💡 Tips for Better Results:\n",
    "- Use repositories with clean, well-structured code\n",
    "- Ensure sufficient GPU memory for larger codebases\n",
    "- Fine-tune the model on domain-specific code\n",
    "- Experiment with different documentation styles\n",
    "- Leverage the RAG system for better context awareness\n",
    "\n",
    "### 🔧 For Production Use:\n",
    "- Set up proper environment variables\n",
    "- Configure logging and monitoring\n",
    "- Implement error handling and retries\n",
    "- Add caching for frequently processed repositories\n",
    "- Consider using the FastAPI backend for scalability"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
